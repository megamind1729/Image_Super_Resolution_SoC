{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming linear regression\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "\n",
    "A,b = [],[]\n",
    "with open('data1.csv','r') as f:\t\t\t# Getting data from csv file as numpy arrays A and b\n",
    "  rows = csv.reader(f)\n",
    "  next(rows)\n",
    "  \n",
    "  for i in rows:\n",
    "    x = []\n",
    "    x.extend([int(j) for j in i[1:-2]])\n",
    "    y = int(i[-2])\t\t\t\t\t# i[-2] for 'mangoes', and i[-1] for oranges \n",
    "    A.append(x)\n",
    "    b.append(y)\n",
    "  \n",
    "A = np.array(A,dtype=np.float64)\n",
    "B = np.array(b,dtype=np.float64)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising data\n",
    "\n",
    "A_mean = np.mean(A,axis=0)\n",
    "A_std = np.std(A,axis=0)\n",
    "A = (A - A_mean)/A_std\n",
    "A = np.insert(A,0,np.ones(len(A)),axis=1)\n",
    "\n",
    "B_mean = np.mean(B,axis=0)\n",
    "B_std = np.std(B,axis=0)\n",
    "B = (B-B_mean)/B_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "\n",
    "A1 = A[0:int(0.7 * len(A))]                         # Training data\n",
    "B1 = B[0:int(0.7 * len(A))]\n",
    "\n",
    "A2 = A[int(0.7 * len(A)):int(0.85 * len(A))]        # Validation data\n",
    "B2 = B[int(0.7 * len(A)):int(0.85 * len(A))]\n",
    "\n",
    "A3 = A[int(0.85 * len(A)):]                         # Test data\n",
    "B3 = B[int(0.85 * len(A)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(A,B,X):\n",
    "  return ((A@X-B.T) @ (A@X-B.T))\n",
    "  \n",
    "def min_cost(A,B):\n",
    "  X_optimum = (np.linalg.inv(A.T @ A)) @ A.T @ B\n",
    "  min_cost = cost(A,B,X_optimum)\n",
    "  return [min_cost,X_optimum] \n",
    "\n",
    "def grad_cost(A,B,X):\n",
    "  return 2 * A.T @ (A@X-B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "eps = 1e-12\n",
    "X = np.full(A1.shape[1],1)\t\t\t\t# Initializing weights\n",
    "#print(cost(A1,B1,X))\n",
    "\n",
    "i = 0\n",
    "  \n",
    "while (True):\t\t\t\t\t\t\n",
    "  i += 1\n",
    "  X_new = X - learning_rate * grad_cost(A1,B1,X)\n",
    "  cost_change = cost(A1,B1,X_new) - cost(A1,B1,X)\n",
    "  \n",
    "  if(math.fabs(cost_change) < eps):\n",
    "    break\n",
    "     \n",
    "  if((cost_change > 0) and learning_rate > 1e-8):\n",
    "    learning_rate /= 2\n",
    "  \n",
    "  X = X_new\n",
    "\n",
    "#  print(cost(A1,B1,X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using gradient descent: \n",
      "Number of iterations:  2091\n",
      "X =  [-3.90600357e-04 -1.60297567e-01  7.49456841e-01  2.46174035e-01]\n",
      "cost =  0.008733330455780007\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "\n",
    "print(\"\\nUsing gradient descent: \")  \n",
    "print(\"Number of iterations: \",i)\n",
    "print(\"X = \", X)\n",
    "print(\"cost = \", cost(A1,B1,X))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimum X and minimum cost (found using linear algebra) for training data : \n",
      "X =  [-3.90528705e-04 -1.60298898e-01  7.49460404e-01  2.46169846e-01]\n",
      "min_cost =  0.008733330366654862 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without using gradient descent\n",
    "\n",
    "min_cost1, X_optimum1 = min_cost(A1,B1)\n",
    "print(\"\\nOptimum X and minimum cost (found using linear algebra) for training data : \")\n",
    "print(\"X = \", X_optimum1)\n",
    "print(\"min_cost = \", min_cost1,'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
